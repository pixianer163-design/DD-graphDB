//! å®æ—¶æµå¤„ç†ç¤ºä¾‹ - ä½¿ç”¨ Differential Dataflow
//! 
//! è¿™ä¸ªç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ differential dataflow è¿›è¡Œå®æ—¶ç¤¾äº¤ç½‘ç»œåˆ†æï¼š
//! - å®æ—¶ PageRank æ›´æ–°
//! - å¢é‡å¼ç¤¾ç¾¤å‘ç°
//! - æµå¼å¥½å‹æ¨è
//! - å®æ—¶å½±å“åŠ›è¿½è¸ª

#[cfg(feature = "streaming")]
use differential_dataflow::{
    collection::Collection,
    input::InputSession,
    operators::{arrange::Arrange, iterate::Iterate},
    AsCollection,
};

#[cfg(feature = "streaming")]
use timely::{
    dataflow::Scope,
    communication::Allocate,
    worker::Worker,
};

use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};
use tracing::{info, debug, error};

use graph_core::{VertexId, Edge, PropertyValue};

/// æµå¼ç¤¾äº¤åˆ†æå¼•æ“
#[cfg(feature = "streaming")]
pub struct StreamingSocialAnalytics {
    /// äº‹ä»¶å‘é€å™¨
    event_sender: mpsc::Sender<StreamEvent>,
    /// ç»“æœæ¥æ”¶å™¨
    result_receiver: Arc<Mutex<mpsc::Receiver<AnalyticsResult>>>,
}

/// æµäº‹ä»¶ç±»å‹
#[derive(Debug, Clone)]
pub enum StreamEvent {
    /// æ·»åŠ ç”¨æˆ·
    AddUser(UserData),
    /// ç§»é™¤ç”¨æˆ·
    RemoveUser(VertexId),
    /// æ·»åŠ å…³ç³»
    AddRelationship(RelationshipData),
    /// ç§»é™¤å…³ç³»
    RemoveRelationship(Edge),
    /// æ›´æ–°ç”¨æˆ·å±æ€§
    UpdateUserProperties(VertexId, HashMap<String, PropertyValue>),
}

/// ç”¨æˆ·æ•°æ®
#[derive(Debug, Clone)]
pub struct UserData {
    pub id: VertexId,
    pub username: String,
    pub properties: HashMap<String, PropertyValue>,
    pub timestamp: u64,
}

/// å…³ç³»æ•°æ®
#[derive(Debug, Clone)]
pub struct RelationshipData {
    pub from: VertexId,
    pub to: VertexId,
    pub rel_type: String,
    pub properties: HashMap<String, PropertyValue>,
    pub timestamp: u64,
}

/// åˆ†æç»“æœ
#[derive(Debug, Clone)]
pub enum AnalyticsResult {
    /// PageRank æ›´æ–°
    PageRankUpdate(Vec<(VertexId, f64)>),
    /// ç¤¾ç¾¤æ›´æ–°
    CommunityUpdate(Vec<(VertexId, u64)>),
    /// å½±å“åŠ›å˜åŒ–
    InfluenceChange(Vec<(VertexId, f64, f64)>), // (user_id, old_score, new_score)
    /// æ¨èåˆ—è¡¨æ›´æ–°
    RecommendationUpdate(VertexId, Vec<(VertexId, f64)>),
    /// ç»Ÿè®¡ä¿¡æ¯
    Statistics(AnalyticsStats),
}

/// åˆ†æç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct AnalyticsStats {
    pub total_vertices: usize,
    pub total_edges: usize,
    pub processed_events: u64,
    pub computation_time_ms: u64,
}

#[cfg(feature = "streaming")]
impl StreamingSocialAnalytics {
    /// åˆ›å»ºæ–°çš„æµå¼åˆ†æå¼•æ“
    pub fn new() -> (Self, StreamingAnalyticsHandle) {
        let (event_tx, event_rx) = mpsc::channel(10000);
        let (result_tx, result_rx) = mpsc::channel(10000);
        
        let handle = StreamingAnalyticsHandle {
            event_receiver: Arc::new(Mutex::new(event_rx)),
            result_sender: result_tx,
        };
        
        let engine = Self {
            event_sender: event_tx,
            result_receiver: Arc::new(Mutex::new(result_rx)),
        };
        
        (engine, handle)
    }
    
    /// å‘é€æµäº‹ä»¶
    pub async fn send_event(&self, event: StreamEvent) -> Result<(), Box<dyn std::error::Error>> {
        self.event_sender.send(event).await
            .map_err(|e| Box::new(e) as Box<dyn std::error::Error>)
    }
    
    /// æ¥æ”¶åˆ†æç»“æœ
    pub async fn receive_results(&self) -> Option<AnalyticsResult> {
        let mut receiver = self.result_receiver.lock().await;
        receiver.recv().await
    }
}

/// æµå¼åˆ†æå¤„ç†å¥æŸ„
#[cfg(feature = "streaming")]
pub struct StreamingAnalyticsHandle {
    event_receiver: Arc<Mutex<mpsc::Receiver<StreamEvent>>>,
    result_sender: mpsc::Sender<AnalyticsResult>,
}

#[cfg(feature = "streaming")]
impl StreamingAnalyticsHandle {
    /// å¯åŠ¨ differential dataflow å¤„ç†
    pub async fn run(self) -> Result<(), Box<dyn std::error::Error>> {
        info!("ğŸš€ å¯åŠ¨ Differential Dataflow æµå¤„ç†å¼•æ“...");
        
        // å¯åŠ¨ timely è®¡ç®—
        timely::execute_from_args(std::env::args(), move |worker| {
            info!("ğŸ‘· å¯åŠ¨ Worker {}", worker.index());
            
            // åˆ›å»ºæ•°æ®æµä½œç”¨åŸŸ
            worker.dataflow::<usize, _, _>(|scope| {
                // åˆ›å»ºè¾“å…¥ä¼šè¯
                let mut vertices_input: InputSession<usize, (VertexId, HashMap<String, PropertyValue>), isize> = 
                    InputSession::new();
                let mut edges_input: InputSession<usize, Edge, isize> = 
                    InputSession::new();
                
                // æ„å»ºé¡¶ç‚¹é›†åˆ
                let vertices = vertices_input.to_collection(scope);
                
                // æ„å»ºè¾¹é›†åˆ
                let edges = edges_input.to_collection(scope);
                
                // 1. å®æ—¶ PageRank è®¡ç®—
                let pagerank = Self::compute_streaming_pagerank(&edges);
                
                // 2. å®æ—¶è¿é€šåˆ†é‡ï¼ˆç¤¾ç¾¤å‘ç°ï¼‰
                let communities = Self::compute_streaming_communities(&edges);
                
                // 3. å®æ—¶ä¸‰è§’å½¢è®¡æ•°ï¼ˆç”¨äºå¥½å‹æ¨èï¼‰
                let triangles = Self::compute_streaming_triangles(&edges);
                
                // 4. å®æ—¶ç›‘æ§å’Œç»Ÿè®¡
                let stats = vertices.count().join(&edges.count());
                
                // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šå°†ç»“æœè¾“å‡ºåˆ°ä¸‹æ¸¸ç³»ç»Ÿ
                // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ‰“å°æ—¥å¿—
                pagerank.inspect(|(v, rank)| {
                    debug!("PageRank: {:?} = {:.6}", v, rank);
                });
                
                communities.inspect(|(v, community)| {
                    debug!("Community: {:?} -> {}", v, community);
                });
                
                // è¿”å›è¾“å…¥ä¼šè¯ä»¥ä¾¿å¤–éƒ¨æ§åˆ¶
                (vertices_input, edges_input)
            });
            
            // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæœ‰ä¸€ä¸ªå¾ªç¯ä» channel æ¥æ”¶äº‹ä»¶å¹¶æ›´æ–°è¾“å…¥
            // ç®€åŒ–ç¤ºä¾‹ï¼š
            info!("âœ… Worker {} æ•°æ®æµæ„å»ºå®Œæˆ", worker.index());
        }).map_err(|e| Box::new(e) as Box<dyn std::error::Error>)?;
        
        Ok(())
    }
    
    /// æµå¼ PageRank è®¡ç®—
    fn compute_streaming_pagerank<G: Scope>(
        edges: &Collection<G, Edge>
    ) -> Collection<G, (VertexId, f64)>
    where
        G::Timestamp: differential_dataflow::lattice::Lattice,
    {
        use differential_dataflow::operators::{Join, Reduce, Threshold};
        
        // è·å–æ‰€æœ‰é¡¶ç‚¹
        let vertices = edges
            .map(|edge| edge.src)
            .concat(&edges.map(|edge| edge.dst))
            .distinct();
        
        // åˆå§‹æ’åï¼šæ¯ä¸ªé¡¶ç‚¹ä¸º 1.0
        let initial_ranks = vertices.map(|v| (v, 1.0));
        
        // è®¡ç®—å‡ºåº¦
        let out_degrees = edges
            .map(|edge| (edge.src, 1isize))
            .reduce(|_src, s, t| {
                let sum: isize = s.iter().map(|(_, d)| *d).sum();
                t.push((sum, 1));
            });
        
        // å‡†å¤‡è¾¹è´¡çŒ®
        let edge_contributions = edges
            .map(|edge| (edge.src, edge.dst))
            .join(&out_degrees)
            .map(|(src, (dst, out_deg))| {
                (dst, (src, 1.0 / out_deg as f64))
            });
        
        // è¿­ä»£è®¡ç®— PageRank
        let damping_factor = 0.85;
        
        initial_ranks.iterate(|ranks| {
            let edge_contrib = edge_contributions.enter(&ranks.scope());
            
            // è®¡ç®—è´¡çŒ®
            let contributions = edge_contrib
                .join_map(ranks, |_dst, (src, contrib), rank| {
                    (*src, *contrib * *rank)
                });
            
            // èšåˆè´¡çŒ®
            let new_ranks = contributions
                .reduce(|_src, s, t| {
                    let total: f64 = s.iter().map(|(_, contrib)| *contrib).sum();
                    t.push((total, 1));
                })
                .map(|(v, total)| {
                    // åº”ç”¨é˜»å°¼å› å­
                    let rank = (1.0 - damping_factor) + damping_factor * total;
                    (v, rank)
                });
            
            new_ranks
        })
    }
    
    /// æµå¼ç¤¾ç¾¤å‘ç°ï¼ˆè¿é€šåˆ†é‡ï¼‰
    fn compute_streaming_communities<G: Scope>(
        edges: &Collection<G, Edge>
    ) -> Collection<G, (VertexId, u64)>
    where
        G::Timestamp: differential_dataflow::lattice::Lattice,
    {
        use differential_dataflow::operators::{Join, Reduce};
        
        // è·å–æ‰€æœ‰é¡¶ç‚¹
        let vertices = edges
            .map(|edge| edge.src)
            .concat(&edges.map(|edge| edge.dst))
            .distinct();
        
        // åˆå§‹ï¼šæ¯ä¸ªé¡¶ç‚¹æ˜¯è‡ªå·±çš„ç¤¾ç¾¤ï¼ˆç”¨é¡¶ç‚¹IDä½œä¸ºç¤¾ç¾¤IDï¼‰
        let initial_components = vertices.map(|v| (v, v.as_u64()));
        
        // è¿­ä»£æ‰¾åˆ°æœ€å°è¿é€šåˆ†é‡
        initial_components.iterate(|components| {
            let edges_in_scope = edges.enter(&components.scope());
            let components_in_scope = components.enter(&components.scope());
            
            // é€šè¿‡è¾¹ä¼ æ’­æœ€å°ç¤¾ç¾¤ID
            let propagated = edges_in_scope
                .map(|edge| (edge.src, edge.dst))
                .join_map(&components_in_scope, |_src, dst, comp| {
                    (*dst, *comp)
                })
                .concat(components_in_scope);
            
            // ä¸ºæ¯ä¸ªé¡¶ç‚¹é€‰æ‹©æœ€å°çš„ç¤¾ç¾¤ID
            propagated
                .reduce(|_v, s, t| {
                    let min_comp = s.iter().map(|(_, comp)| *comp).min().unwrap();
                    t.push((min_comp, 1));
                })
                .map(|(v, comp)| (v, comp))
        })
    }
    
    /// æµå¼ä¸‰è§’å½¢è®¡æ•°ï¼ˆç”¨äºå…±åŒå¥½å‹æ¨èï¼‰
    fn compute_streaming_triangles<G: Scope>(
        edges: &Collection<G, Edge>
    ) -> Collection<G, (VertexId, VertexId, VertexId)>
    where
        G::Timestamp: differential_dataflow::lattice::Lattice,
    {
        use differential_dataflow::operators::Join;
        
        // å°†è¾¹è§†ä¸ºæ— å‘ï¼ˆæ·»åŠ åå‘è¾¹ï¼‰
        let undirected_edges = edges
            .concat(&edges.map(|edge| Edge::new(edge.dst, edge.src, &edge.label)));
        
        // æŸ¥æ‰¾ä¸‰è§’å½¢ï¼šå¦‚æœ A-B å’Œ B-Cï¼Œæ£€æŸ¥ A-C
        let edges_forward = undirected_edges.map(|edge| (edge.src, edge.dst));
        let edges_reverse = undirected_edges.map(|edge| (edge.dst, edge.src));
        
        // é€šè¿‡è¿æ¥æ‰¾åˆ°ä¸‰è§’å½¢
        edges_forward
            .join(&edges_forward)
            .map(|(b, (a, c))| (a, b, c))
            .filter(|(a, b, c)| a < b && b < c) // è§„èŒƒåŒ–ï¼Œé¿å…é‡å¤
    }
    
    /// è®¡ç®—å®æ—¶å½±å“åŠ›å˜åŒ–
    fn compute_influence_changes<G: Scope>(
        current_ranks: &Collection<G, (VertexId, f64)>,
        previous_ranks: &Collection<G, (VertexId, f64)>,
    ) -> Collection<G, (VertexId, f64, f64)>
    where
        G::Timestamp: differential_dataflow::lattice::Lattice,
    {
        use differential_dataflow::operators::Join;
        
        // è¿æ¥å½“å‰å’Œä¹‹å‰çš„æ’åï¼Œè®¡ç®—å˜åŒ–
        current_ranks
            .join(previous_ranks)
            .map(|(v, (current, previous))| (v, previous, current))
            .filter(|(_, previous, current)| (current - previous).abs() > 0.001)
    }
}

/// å®æ—¶æ¨èå¼•æ“
#[cfg(feature = "streaming")]
pub struct RealtimeRecommendationEngine {
    analytics: StreamingSocialAnalytics,
}

#[cfg(feature = "streaming")]
impl RealtimeRecommendationEngine {
    /// åˆ›å»ºæ–°çš„æ¨èå¼•æ“
    pub fn new() -> (Self, StreamingAnalyticsHandle) {
        let (analytics, handle) = StreamingSocialAnalytics::new();
        
        let engine = Self { analytics };
        (engine, handle)
    }
    
    /// ä¸ºç”¨æˆ·è·å–å®æ—¶æ¨è
    pub async fn get_recommendations(&self, user_id: VertexId, limit: usize) 
        -> Result<Vec<(VertexId, f64)>, Box<dyn std::error::Error>> {
        
        // è¯·æ±‚åˆ†æç»“æœ
        // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™ä¼šæŸ¥è¯¢ç‰©åŒ–è§†å›¾æˆ–ç¼“å­˜
        
        // ç®€åŒ–ç¤ºä¾‹ï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®
        let recommendations: Vec<(VertexId, f64)> = (1..=limit)
            .map(|i| (VertexId::new(i as u64), 1.0 / i as f64))
            .collect();
        
        Ok(recommendations)
    }
    
    /// å¤„ç†ç”¨æˆ·æ´»åŠ¨äº‹ä»¶
    pub async fn process_activity(&self, event: StreamEvent) -> Result<(), Box<dyn std::error::Error>> {
        self.analytics.send_event(event).await
    }
}

/// æ¼”ç¤ºæµå¤„ç†
pub async fn run_streaming_demo() -> Result<(), Box<dyn std::error::Error>> {
    info!("ğŸŒŠ å¯åŠ¨ Differential Dataflow æµå¤„ç†æ¼”ç¤º...");
    
    #[cfg(feature = "streaming")]
    {
        // åˆ›å»ºæµå¼åˆ†æå¼•æ“
        let (analytics, handle) = StreamingSocialAnalytics::new();
        
        // åœ¨åå°å¯åŠ¨å¤„ç†
        tokio::spawn(async move {
            if let Err(e) = handle.run().await {
                error!("âŒ æµå¤„ç†å¼•æ“é”™è¯¯: {}", e);
            }
        });
        
        // æ¨¡æ‹Ÿå®æ—¶äº‹ä»¶æµ
        let events = vec![
            StreamEvent::AddUser(UserData {
                id: VertexId::new(1),
                username: "alice".to_string(),
                properties: HashMap::new(),
                timestamp: 1,
            }),
            StreamEvent::AddUser(UserData {
                id: VertexId::new(2),
                username: "bob".to_string(),
                properties: HashMap::new(),
                timestamp: 2,
            }),
            StreamEvent::AddUser(UserData {
                id: VertexId::new(3),
                username: "carol".to_string(),
                properties: HashMap::new(),
                timestamp: 3,
            }),
            StreamEvent::AddRelationship(RelationshipData {
                from: VertexId::new(1),
                to: VertexId::new(2),
                rel_type: "follows".to_string(),
                properties: HashMap::new(),
                timestamp: 4,
            }),
            StreamEvent::AddRelationship(RelationshipData {
                from: VertexId::new(2),
                to: VertexId::new(3),
                rel_type: "follows".to_string(),
                properties: HashMap::new(),
                timestamp: 5,
            }),
            StreamEvent::AddRelationship(RelationshipData {
                from: VertexId::new(3),
                to: VertexId::new(1),
                rel_type: "follows".to_string(),
                properties: HashMap::new(),
                timestamp: 6,
            }),
        ];
        
        // å‘é€äº‹ä»¶
        for event in events {
            info!("ğŸ“¤ å‘é€äº‹ä»¶: {:?}", event);
            analytics.send_event(event).await?;
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
        
        // ç­‰å¾…å¹¶æ˜¾ç¤ºç»“æœ
        info!("â³ ç­‰å¾…åˆ†æç»“æœ...");
        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
        
        // å°è¯•æ¥æ”¶ç»“æœ
        while let Ok(Some(result)) = tokio::time::timeout(
            tokio::time::Duration::from_secs(1),
            analytics.receive_results()
        ).await {
            info!("ğŸ“Š åˆ†æç»“æœ: {:?}", result);
        }
        
        info!("âœ… æµå¤„ç†æ¼”ç¤ºå®Œæˆ");
    }
    
    #[cfg(not(feature = "streaming"))]
    {
        info!("âš ï¸ streaming ç‰¹æ€§æœªå¯ç”¨ï¼Œè·³è¿‡æµå¤„ç†æ¼”ç¤º");
        info!("ğŸ’¡ ä½¿ç”¨ --features streaming å¯ç”¨æµå¤„ç†åŠŸèƒ½");
    }
    
    Ok(())
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();
    
    // è¿è¡Œæµå¤„ç†æ¼”ç¤º
    run_streaming_demo().await?;
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_stream_event_creation() {
        let event = StreamEvent::AddUser(UserData {
            id: VertexId::new(1),
            username: "test".to_string(),
            properties: HashMap::new(),
            timestamp: 1,
        });
        
        match event {
            StreamEvent::AddUser(user) => {
                assert_eq!(user.id, VertexId::new(1));
                assert_eq!(user.username, "test");
            }
            _ => panic!("é”™è¯¯çš„äº‹ä»¶ç±»å‹"),
        }
    }
    
    #[test]
    fn test_relationship_data() {
        let rel = RelationshipData {
            from: VertexId::new(1),
            to: VertexId::new(2),
            rel_type: "follows".to_string(),
            properties: HashMap::new(),
            timestamp: 1,
        };
        
        assert_eq!(rel.from, VertexId::new(1));
        assert_eq!(rel.to, VertexId::new(2));
        assert_eq!(rel.rel_type, "follows");
    }
}
